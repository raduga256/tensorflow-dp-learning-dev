{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "05_transfer_learning_in_tensorflow_fine_tuning.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNgkSzWr7nur0w/7qT0yeH+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/raduga256/tensorflow-dp-learning-dev/blob/main/05_transfer_learning_in_tensorflow_fine_tuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Transfer Learning with Tensorflow Part 2: Fine-Tuning\n",
        "\n",
        "In the previous notebook, we covered transfer learning feature extraction, now it's time to learn tranfer learning: fine-tuning"
      ],
      "metadata": {
        "id": "HKHXYR-xtY2S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check gpu\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "YIMRCcWHuX9v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating helper functions\n",
        "In the previous notebooks, we've created a bunch of helper functions, now we could rewrite them all, however, this is tedious\n",
        "\n",
        "It is a good idea to put functions you'll want to use again in a script you can download and import into your notebooks (or elsewhere). \n",
        "We have done this for functions we have used previously\n",
        "\n",
        "**Note:** How to create a python file (.py) using google colab\n",
        "\n",
        "Video Link: https://youtu.be/fPDGu1kQCzE"
      ],
      "metadata": {
        "id": "LWZMJz2MvBHd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile helper_functions.py\n",
        "#!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n",
        "### We create a bunch of helpful functions throughout the course.\n",
        "### Storing them here so they're easily accessible.\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "# Create a function to import an image and resize it to be able to be used with our model\n",
        "def load_and_prep_image(filename, img_shape=224, scale=True):\n",
        "  \"\"\"\n",
        "  Reads in an image from filename, turns it into a tensor and reshapes into\n",
        "  (224, 224, 3).\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  filename (str): string filename of target image\n",
        "  img_shape (int): size to resize target image to, default 224\n",
        "  scale (bool): whether to scale pixel values to range(0, 1), default True\n",
        "  \"\"\"\n",
        "  # Read in the image\n",
        "  img = tf.io.read_file(filename)\n",
        "  # Decode it into a tensor\n",
        "  img = tf.image.decode_jpeg(img)\n",
        "  # Resize the image\n",
        "  img = tf.image.resize(img, [img_shape, img_shape])\n",
        "  if scale:\n",
        "    # Rescale the image (get all values between 0 and 1)\n",
        "    return img/255.\n",
        "  else:\n",
        "    return img\n",
        "\n",
        "# Note: The following confusion matrix code is a remix of Scikit-Learn's \n",
        "# plot_confusion_matrix function - https://scikit-learn.org/stable/modules/generated/sklearn.metrics.plot_confusion_matrix.html\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Our function needs a different name to sklearn's plot_confusion_matrix\n",
        "def make_confusion_matrix(y_true, y_pred, classes=None, figsize=(10, 10), text_size=15, norm=False, savefig=False): \n",
        "  \"\"\"Makes a labelled confusion matrix comparing predictions and ground truth labels.\n",
        "\n",
        "  If classes is passed, confusion matrix will be labelled, if not, integer class values\n",
        "  will be used.\n",
        "\n",
        "  Args:\n",
        "    y_true: Array of truth labels (must be same shape as y_pred).\n",
        "    y_pred: Array of predicted labels (must be same shape as y_true).\n",
        "    classes: Array of class labels (e.g. string form). If `None`, integer labels are used.\n",
        "    figsize: Size of output figure (default=(10, 10)).\n",
        "    text_size: Size of output figure text (default=15).\n",
        "    norm: normalize values or not (default=False).\n",
        "    savefig: save confusion matrix to file (default=False).\n",
        "  \n",
        "  Returns:\n",
        "    A labelled confusion matrix plot comparing y_true and y_pred.\n",
        "\n",
        "  Example usage:\n",
        "    make_confusion_matrix(y_true=test_labels, # ground truth test labels\n",
        "                          y_pred=y_preds, # predicted labels\n",
        "                          classes=class_names, # array of class label names\n",
        "                          figsize=(15, 15),\n",
        "                          text_size=10)\n",
        "  \"\"\"  \n",
        "  # Create the confustion matrix\n",
        "  cm = confusion_matrix(y_true, y_pred)\n",
        "  cm_norm = cm.astype(\"float\") / cm.sum(axis=1)[:, np.newaxis] # normalize it\n",
        "  n_classes = cm.shape[0] # find the number of classes we're dealing with\n",
        "\n",
        "  # Plot the figure and make it pretty\n",
        "  fig, ax = plt.subplots(figsize=figsize)\n",
        "  cax = ax.matshow(cm, cmap=plt.cm.Blues) # colors will represent how 'correct' a class is, darker == better\n",
        "  fig.colorbar(cax)\n",
        "\n",
        "  # Are there a list of classes?\n",
        "  if classes:\n",
        "    labels = classes\n",
        "  else:\n",
        "    labels = np.arange(cm.shape[0])\n",
        "  \n",
        "  # Label the axes\n",
        "  ax.set(title=\"Confusion Matrix\",\n",
        "         xlabel=\"Predicted label\",\n",
        "         ylabel=\"True label\",\n",
        "         xticks=np.arange(n_classes), # create enough axis slots for each class\n",
        "         yticks=np.arange(n_classes), \n",
        "         xticklabels=labels, # axes will labeled with class names (if they exist) or ints\n",
        "         yticklabels=labels)\n",
        "  \n",
        "  # Make x-axis labels appear on bottom\n",
        "  ax.xaxis.set_label_position(\"bottom\")\n",
        "  ax.xaxis.tick_bottom()\n",
        "\n",
        "  # Set the threshold for different colors\n",
        "  threshold = (cm.max() + cm.min()) / 2.\n",
        "\n",
        "  # Plot the text on each cell\n",
        "  for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "    if norm:\n",
        "      plt.text(j, i, f\"{cm[i, j]} ({cm_norm[i, j]*100:.1f}%)\",\n",
        "              horizontalalignment=\"center\",\n",
        "              color=\"white\" if cm[i, j] > threshold else \"black\",\n",
        "              size=text_size)\n",
        "    else:\n",
        "      plt.text(j, i, f\"{cm[i, j]}\",\n",
        "              horizontalalignment=\"center\",\n",
        "              color=\"white\" if cm[i, j] > threshold else \"black\",\n",
        "              size=text_size)\n",
        "\n",
        "  # Save the figure to the current working directory\n",
        "  if savefig:\n",
        "    fig.savefig(\"confusion_matrix.png\")\n",
        "  \n",
        "# Make a function to predict on images and plot them (works with multi-class)\n",
        "def pred_and_plot(model, filename, class_names):\n",
        "  \"\"\"\n",
        "  Imports an image located at filename, makes a prediction on it with\n",
        "  a trained model and plots the image with the predicted class as the title.\n",
        "  \"\"\"\n",
        "  # Import the target image and preprocess it\n",
        "  img = load_and_prep_image(filename)\n",
        "\n",
        "  # Make a prediction\n",
        "  pred = model.predict(tf.expand_dims(img, axis=0))\n",
        "\n",
        "  # Get the predicted class\n",
        "  if len(pred[0]) > 1: # check for multi-class\n",
        "    pred_class = class_names[pred.argmax()] # if more than one output, take the max\n",
        "  else:\n",
        "    pred_class = class_names[int(tf.round(pred)[0][0])] # if only one output, round\n",
        "\n",
        "  # Plot the image and predicted class\n",
        "  plt.imshow(img)\n",
        "  plt.title(f\"Prediction: {pred_class}\")\n",
        "  plt.axis(False);\n",
        "  \n",
        "import datetime\n",
        "\n",
        "def create_tensorboard_callback(dir_name, experiment_name):\n",
        "  \"\"\"\n",
        "  Creates a TensorBoard callback instand to store log files.\n",
        "\n",
        "  Stores log files with the filepath:\n",
        "    \"dir_name/experiment_name/current_datetime/\"\n",
        "\n",
        "  Args:\n",
        "    dir_name: target directory to store TensorBoard log files\n",
        "    experiment_name: name of experiment directory (e.g. efficientnet_model_1)\n",
        "  \"\"\"\n",
        "  log_dir = dir_name + \"/\" + experiment_name + \"/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "  tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
        "      log_dir=log_dir\n",
        "  )\n",
        "  print(f\"Saving TensorBoard log files to: {log_dir}\")\n",
        "  return tensorboard_callback\n",
        "\n",
        "# Plot the validation and training data separately\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_loss_curves(history):\n",
        "  \"\"\"\n",
        "  Returns separate loss curves for training and validation metrics.\n",
        "\n",
        "  Args:\n",
        "    history: TensorFlow model History object (see: https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/History)\n",
        "  \"\"\" \n",
        "  loss = history.history['loss']\n",
        "  val_loss = history.history['val_loss']\n",
        "\n",
        "  accuracy = history.history['accuracy']\n",
        "  val_accuracy = history.history['val_accuracy']\n",
        "\n",
        "  epochs = range(len(history.history['loss']))\n",
        "\n",
        "  # Plot loss\n",
        "  plt.plot(epochs, loss, label='training_loss')\n",
        "  plt.plot(epochs, val_loss, label='val_loss')\n",
        "  plt.title('Loss')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.legend()\n",
        "\n",
        "  # Plot accuracy\n",
        "  plt.figure()\n",
        "  plt.plot(epochs, accuracy, label='training_accuracy')\n",
        "  plt.plot(epochs, val_accuracy, label='val_accuracy')\n",
        "  plt.title('Accuracy')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.legend();\n",
        "\n",
        "def compare_historys(original_history, new_history, initial_epochs=5):\n",
        "    \"\"\"\n",
        "    Compares two TensorFlow model History objects.\n",
        "    \n",
        "    Args:\n",
        "      original_history: History object from original model (before new_history)\n",
        "      new_history: History object from continued model training (after original_history)\n",
        "      initial_epochs: Number of epochs in original_history (new_history plot starts from here) \n",
        "    \"\"\"\n",
        "    \n",
        "    # Get original history measurements\n",
        "    acc = original_history.history[\"accuracy\"]\n",
        "    loss = original_history.history[\"loss\"]\n",
        "\n",
        "    val_acc = original_history.history[\"val_accuracy\"]\n",
        "    val_loss = original_history.history[\"val_loss\"]\n",
        "\n",
        "    # Combine original history with new history\n",
        "    total_acc = acc + new_history.history[\"accuracy\"]\n",
        "    total_loss = loss + new_history.history[\"loss\"]\n",
        "\n",
        "    total_val_acc = val_acc + new_history.history[\"val_accuracy\"]\n",
        "    total_val_loss = val_loss + new_history.history[\"val_loss\"]\n",
        "\n",
        "    # Make plots\n",
        "    plt.figure(figsize=(8, 8))\n",
        "    plt.subplot(2, 1, 1)\n",
        "    plt.plot(total_acc, label='Training Accuracy')\n",
        "    plt.plot(total_val_acc, label='Validation Accuracy')\n",
        "    plt.plot([initial_epochs-1, initial_epochs-1],\n",
        "              plt.ylim(), label='Start Fine Tuning') # reshift plot around epochs\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.title('Training and Validation Accuracy')\n",
        "\n",
        "    plt.subplot(2, 1, 2)\n",
        "    plt.plot(total_loss, label='Training Loss')\n",
        "    plt.plot(total_val_loss, label='Validation Loss')\n",
        "    plt.plot([initial_epochs-1, initial_epochs-1],\n",
        "              plt.ylim(), label='Start Fine Tuning') # reshift plot around epochs\n",
        "    plt.legend(loc='upper right')\n",
        "    plt.title('Training and Validation Loss')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.show()\n",
        "  \n",
        "# Create function to unzip a zipfile into current working directory \n",
        "# (since we're going to be downloading and unzipping a few files)\n",
        "import zipfile\n",
        "\n",
        "def unzip_data(filename):\n",
        "  \"\"\"\n",
        "  Unzips filename into the current working directory.\n",
        "\n",
        "  Args:\n",
        "    filename (str): a filepath to a target zip folder to be unzipped.\n",
        "  \"\"\"\n",
        "  zip_ref = zipfile.ZipFile(filename, \"r\")\n",
        "  zip_ref.extractall()\n",
        "  zip_ref.close()\n",
        "\n",
        "# Walk through an image classification directory and find out how many files (images)\n",
        "# are in each subdirectory.\n",
        "import os\n",
        "\n",
        "def walk_through_dir(dir_path):\n",
        "  \"\"\"\n",
        "  Walks through dir_path returning its contents.\n",
        "\n",
        "  Args:\n",
        "    dir_path (str): target directory\n",
        "  \n",
        "  Returns:\n",
        "    A print out of:\n",
        "      number of subdiretories in dir_path\n",
        "      number of images (files) in each subdirectory\n",
        "      name of each subdirectory\n",
        "  \"\"\"\n",
        "  for dirpath, dirnames, filenames in os.walk(dir_path):\n",
        "    print(f\"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'.\")\n",
        "    \n",
        "# Function to evaluate: accuracy, precision, recall, f1-score\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "def calculate_results(y_true, y_pred):\n",
        "  \"\"\"\n",
        "  Calculates model accuracy, precision, recall and f1 score of a binary classification model.\n",
        "\n",
        "  Args:\n",
        "      y_true: true labels in the form of a 1D array\n",
        "      y_pred: predicted labels in the form of a 1D array\n",
        "\n",
        "  Returns a dictionary of accuracy, precision, recall, f1-score.\n",
        "  \"\"\"\n",
        "  # Calculate model accuracy\n",
        "  model_accuracy = accuracy_score(y_true, y_pred) * 100\n",
        "  # Calculate model precision, recall and f1 score using \"weighted average\n",
        "  model_precision, model_recall, model_f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"weighted\")\n",
        "  model_results = {\"accuracy\": model_accuracy,\n",
        "                  \"precision\": model_precision,\n",
        "                  \"recall\": model_recall,\n",
        "                  \"f1\": model_f1}\n",
        "  return model_results"
      ],
      "metadata": {
        "id": "FGt5xMELvU-a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import helper functions we're going to use in this notebook \n",
        "from helper_functions import create_tensorboard_callback, plot_loss_curves, unzip_data, walk_through_dir"
      ],
      "metadata": {
        "id": "whwOsZOE8eRr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> ✈ **Note:** If you're running this notebook in Google Colab, when it times out Colab will delete `helper_functions.py`, so you'll have to redownload it if you want access to helper functions."
      ],
      "metadata": {
        "id": "VLiNuWRP9NFq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Let's get some data\n",
        "\n",
        "This time we're going to see how we can use the pretrained models within tf.keras.applications and apply them to our own models (recognizing images of food)\n",
        "Link: https://keras.io/api/applications/\n"
      ],
      "metadata": {
        "id": "KFkXNqqn91lq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get 10% of training data of 10 classes of Food101\n",
        "!wget https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_10_percent.zip\n",
        "\n",
        "unzip_data(\"10_food_classes_10_percent.zip\")"
      ],
      "metadata": {
        "id": "f17YlMB_-Ex2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check out how many images and subdirectories in our dataset\n",
        "walk_through_dir(\"10_food_classes_10_percent\")"
      ],
      "metadata": {
        "id": "Aj0P62w8mfxP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create training and testing directory paths\n",
        "train_dir = \"10_food_classes_10_percent/train\"\n",
        "test_dir = \"10_food_classes_10_percent/test\""
      ],
      "metadata": {
        "id": "Nha4LGUTm7H4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "IMG_SIZE = (224, 224)\n",
        "BATCH_SIZE = 32\n",
        "train_data_10_percent = tf.keras.preprocessing.image_dataset_from_directory(directory=train_dir,\n",
        "                                                                            image_size=IMG_SIZE,\n",
        "                                                                            label_mode=\"categorical\",\n",
        "                                                                            batch_size=BATCH_SIZE)\n",
        "test_data = tf.keras.preprocessing.image_dataset_from_directory(directory=test_dir,\n",
        "                                                                image_size=IMG_SIZE,\n",
        "                                                                label_mode=\"categorical\",\n",
        "                                                                batch_size=BATCH_SIZE)"
      ],
      "metadata": {
        "id": "SbFy-xwRnSqi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_10_percent"
      ],
      "metadata": {
        "id": "nlvBUClYpE8w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check out class names of our dataset\n",
        "train_data_10_percent.class_names"
      ],
      "metadata": {
        "id": "yEGUf3nLrSmT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# See an example of a batch of data\n",
        "for images, labels in train_data_10_percent.take(1):\n",
        "  print(images, labels)"
      ],
      "metadata": {
        "id": "vwzPmnRUrs9J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model 0: Building a transfer learning feature extraction model using the Keras Functional API\n",
        "\n",
        "The sequentil API is straight-forward, it runs our layers in sequential order.\n",
        "But the functional API gives us more flexibility with our models - https://keras.io/guides/functional_api/"
      ],
      "metadata": {
        "id": "x6KtxOEjR7yy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Create a base model with tf.keras.applications\n",
        "base_model = tf.keras.applications.EfficientNetB0(include_top=False)\n",
        "\n",
        "# 2. Freeze the base model (so the underlying pre-trained patterns aren't updated during training)\n",
        "base_model.trainable = False\n",
        "\n",
        "# 3. Create inputs into our model\n",
        "inputs = tf.keras.layers.Input(shape=(224, 224, 3), name=\"input_layer\")\n",
        "\n",
        "# 4. If using a modle like ResNet50V2 you will need to normalize inputs (you don't have to for EfficientNet)\n",
        "# x = tf.keras.layers.experimental.preprocessing.Rescaling(1/255.)(inputs)\n",
        "\n",
        "# 5. Pass the inputs into the base_model\n",
        "x = base_model(inputs)\n",
        "print(f\"Shape after passing inputs through base model: {x.shape}\")\n",
        "\n",
        "# 6. Average pool the outputs of the model (aggregate all the most important information to reduce the numnber of computations)\n",
        "x = tf.keras.layers.GlobalAveragePooling2D(name=\"global_average_pooling\")(x)\n",
        "print(f\"Shape after GlobalAveragePooling2D: {x.shape}\")\n",
        "\n",
        "# 7. Create the output activation layer\n",
        "outputs = tf.keras.layers.Dense(10, activation=\"softmax\", name=\"output_layer\")(x)\n",
        "\n",
        "# 8. Combine the inputs with the outputs into a model\n",
        "model_0 = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "# 9. Compile the model\n",
        "model_0.compile(loss=\"categorical_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "# 10. Fit the model\n",
        "history_model_0 = model_0.fit(train_data_10_percent,\n",
        "                              epochs=5,\n",
        "                              steps_per_epoch=len(train_data_10_percent),\n",
        "                              validation_data=test_data,\n",
        "                              validation_steps=int(0.25 * len(test_data)),\n",
        "                              callbacks=create_tensorboard_callback(dir_name=\"transfer_learning\", experiment_name=\"10_percent_feature_extraction\")) "
      ],
      "metadata": {
        "id": "C-F9dqQdU8x0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate on the full test dataset\n",
        "model_0.evaluate(test_data)"
      ],
      "metadata": {
        "id": "7Gin4Ev1mlTX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check the layers in our base model\n",
        "for layer_number, layer in enumerate(base_model.layers):\n",
        "  print(layer_number, layer.name)"
      ],
      "metadata": {
        "id": "pj49Y9wHnOph"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# How about we get a summary of the base model\n",
        "base_model.summary()"
      ],
      "metadata": {
        "id": "kFS2UikrotPJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# How about a summary of our whole model?\n",
        "model_0.summary()"
      ],
      "metadata": {
        "id": "DSqZUzZto88i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check out our model's training curves\n",
        "plot_loss_curves(history_model_0)"
      ],
      "metadata": {
        "id": "56KUVVBqpT-i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Getting a feature vector from a trained model\n",
        "\n",
        "Let's demonstrate the Global Average Pooling 2D layer...\n",
        "\n",
        "We hav a tensor after our model goes through `base_model` of shape (None, 7, 7, 1280).\n",
        "\n",
        "But then when it passes through GlobalAveragePooling2D, it turns into (None, 1280)\n",
        "\n",
        "Let's use a similar shaped tensor of (1, 4, 4, 3) and then pass it to GlobalAveragePooling2D"
      ],
      "metadata": {
        "id": "LgrXHNyHptwN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the input shape\n",
        "input_shape = (1, 4, 4, 3)\n",
        "\n",
        "# Create a random tensor\n",
        "tf.random.set_seed(42)\n",
        "input_tensor = tf.random.normal(input_shape)\n",
        "print(f\"Random input tensor: \\n {input_tensor}\\n\")\n",
        "\n",
        "# Pass the random tensor through a global average pooling 2D layer\n",
        "global_average_pooled_tensor = tf.keras.layers.GlobalAveragePooling2D()(input_tensor)\n",
        "print(f\"2D global average pooled random tensor:\\n{global_average_pooled_tensor} \\n\")\n",
        "\n",
        "# Check the shape of the different tensors\n",
        "print(f\"Shape of input tensor: {input_tensor.shape}\")\n",
        "print(f\"Shape of Global Average Pooled 2D tensor: {global_average_pooled_tensor.shape}\")"
      ],
      "metadata": {
        "id": "XhwN4eKAp_qs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's replicate the GlobalAveragePol2D layer\n",
        "tf.reduce_mean(input_tensor, axis=[1, 2])"
      ],
      "metadata": {
        "id": "DM8ZqKRvt0Wj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "◀**Practice:** Try to do the same with the above two cells but this time use `GlobalMaxPool2D`... and see what happens."
      ],
      "metadata": {
        "id": "rWU8Qol0upRv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "✈**Note:** One of the reasons feature extraction transfer learning is named how it is, is because what often happens is pretrained model outs a feature vector a long tensor of numbers which represents the learned representation of the model on a particular sample. In our case, this is the output of the `tf.keras.layers.GlobalAveragePooling2D` layer which can then be used to extract patterns out for our own specific problem."
      ],
      "metadata": {
        "id": "ItpPliSpvaM2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Running a series of transfer learning experiments\n",
        "\n",
        "We've seen the incredible results transfer learnig can get with only 10% of the training data, but how does it go with 1% of the training data ... how about we set up a bunch of experiments to find out:\n",
        "\n",
        "1. `model_1` - use feature extraction transfer learning with 1% of the training data with data augmentation.\n",
        "2. `model_2` - use feature extraction transfer learning with 10% of the training with data augmentation.\n",
        "3. `model_3` - use fine-tuning transfer learning on 10% of the training data with data augmentation\n",
        "4. `modle_4` - use fine-tuning transfer learning on 100% of the training data with data augmentation\n",
        "\n",
        "> ✈**Note:** Throughout all experiments, the same test dataset will be used to evaluate our model... this ensures consistency accross evaluation metrics. "
      ],
      "metadata": {
        "id": "xMJjfQFqw8kF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download and unzip data - preprocessed from Food101\n",
        "!wget https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_1_percent.zip\n",
        "\n",
        "# Unzip the data with zipfile package in the helper_function.py \n",
        "unzip_data(\"10_food_classes_1_percent.zip\")"
      ],
      "metadata": {
        "id": "o-NR1JZO1BQy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create training and test dirs\n",
        "train_dir_1_percent = \"10_food_classes_1_percent/train\"\n",
        "test_dir = \"10_food_classes_1_percent/test\""
      ],
      "metadata": {
        "id": "b8ZXEPFU1yE9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# inspect, how many images are we working with\n",
        "walk_through_dir(\"10_food_classes_1_percent\")"
      ],
      "metadata": {
        "id": "5kjpr-wF2FkV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup data loaders\n",
        "IMG_SIZE = (224, 224)\n",
        "train_data_1_percent = tf.keras.preprocessing.image_dataset_from_directory(train_dir_1_percent,\n",
        "                                                                           label_mode=\"categorical\",\n",
        "                                                                           image_size=IMG_SIZE,\n",
        "                                                                           batch_size=BATCH_SIZE)\n",
        "# Test data loader\n",
        "test_data = tf.keras.preprocessing.image_dataset_from_directory(test_dir, \n",
        "                                                                label_mode=\"categorical\",\n",
        "                                                                image_size=IMG_SIZE,\n",
        "                                                                batch_size=BATCH_SIZE)\n"
      ],
      "metadata": {
        "id": "VGRPwalA2Zoj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tf.__version__)"
      ],
      "metadata": {
        "id": "3J6iw09L9Vsh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Adding data augmentatio right into the model\n",
        "\n",
        "To add data augmentation right into our modles, we can use the layers inside:\n",
        "\n",
        "* `tf.keras.layers.experimentatl.preprocessing()`\n",
        "\n",
        "We can see the benefits of doing this within \n",
        "the TensorFlow Data augmentation \n",
        "\n",
        "documentation: https://www.tensorflow.org/tutorials/images/data_augmentation\n",
        "\n",
        "**Note: Advantages** off the top of heads, after reading the docs, the benefits of using data augmentation inside the model are:\n",
        "* preprocessing of images (augmenting them) happens on the GPU (much faster) rather than the CPU.\n",
        "* Image data augmentation only happens during training, so we can still export our whole model and use it elsewhere"
      ],
      "metadata": {
        "id": "0BtnLueI8fQh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers.experimental import preprocessing\n",
        "\n",
        "# Create data augmentation stage with horizontal flipping,  rotations, zoom, etc\n",
        "data_augmentation = keras.Sequential([\n",
        "                                      preprocessing.RandomFlip(\"horizontal\"),\n",
        "                                      preprocessing.RandomRotation(0.2),\n",
        "                                      preprocessing.RandomZoom(0.2),\n",
        "                                      preprocessing.RandomHeight(0.2),\n",
        "                                      preprocessing.RandomWidth(0.2)\n",
        "                                      # preprocessing.Rescale(1/255.) # Keep for models like ResNet50V2 but EfficientNetB0 does'nt need it\n",
        "], name=\"data_augmentation\")\n"
      ],
      "metadata": {
        "id": "TA-383aj9wmq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualize our data augmentation layer (and see what happens to our data)"
      ],
      "metadata": {
        "id": "9wr0Lmwt9O-g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# View a random image and compare it to its augmented version\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import os\n",
        "import random\n"
      ],
      "metadata": {
        "id": "uhLCbFFyLNfe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}